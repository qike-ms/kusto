////////////////////////////////////////////
// AKS provisioning QoS and error analysis
////////////////////////////////////////////

// Check how many CREATEs with AAD
AsyncQoSEvents
| where TIMESTAMP > ago(7d)
| where operationName == "PutManagedClusterHandler.PUT" and suboperationName == 'Creating'
| extend bag = todynamic(propertiesBag)
| summarize count() by tobool(bag.aadEnabled)


//////////////////////////////////////
// Debug errors for 1 CLUSTER
//////////////////////////////////////
let subid='103f9b41-f726-46ba-9d75-0dc77a591b9f';
let cluster='y2-fr-fmfi1-k8s-cluster1';
union FrontEndContextActivity, AsyncContextActivity
| where PreciseTimeStamp >= datetime(2019-09-19 00:00:00) and PreciseTimeStamp <= datetime(2019-09-28 23:59:59)
| where subscriptionID == subid
//| where resourceGroupName contains "CIRC-AZUR-DMZ-IGNITE"
//| where operationName contains "PUT"
| where resourceName == ['cluster']
| extend Message = parse_json(msg)
| where level != "info"
| project operationID, PreciseTimeStamp, level, code=tostring(Message.code), suboperationName, msg, operationName, correlationID, region, fileName, resourceName, resourceGroupName, subscriptionID
| join kind=leftouter  AsyncQoSEvents on subscriptionID, resourceGroupName, resourceName, operationName, suboperationName, operationID
| sort by subscriptionID, resourceGroupName, resourceName, operationID, suboperationName, PreciseTimeStamp desc 

//////////////////////////////////////
// Provisioning errors for 1 OPERATION
//////////////////////////////////////
union FrontEndContextActivity, AsyncContextActivity
| where PreciseTimeStamp >= datetime(2019-09-19 00:00:00) and PreciseTimeStamp <= datetime(2019-09-26 23:59:59)
| where subscriptionID contains "af1c88ae-c328-44f3-908b-608dfb0004d5"
| where resourceGroupName contains "CIRC-AZUR-DMZ-IGNITE"
| where resourceName contains "k8s-aresignite" 
| where operationID contains "93ec4095-b869-4720-9383-a4117441bb70"
| extend Message = parse_json(msg)
| where operationName contains "PUT"
| where level != "info"
| project PreciseTimeStamp, level, code=tostring(Message.code), suboperationName, msg, operationName, operationID, correlationID, region, fileName, resourceName, resourceGroupName


//////////////////////////////////////
// Latency analysis

// My Prober latency
AsyncQoSEvents
| where PreciseTimeStamp > ago(7d)
| where result == "Succeeded"
| where operationName contains "ManagedCluster" and suboperationName == "Creating"
| where resourceGroupName == 'qike_eastus' and resourceName startswith_cs "prober"
| project PreciseTimeStamp, minutes=latency/60000.
| render timechart 

// Latency excluding runners
AsyncQoSEvents
| where PreciseTimeStamp > ago(1d)
| where result == "Succeeded"
| where operationName contains "ManagedCluster" and suboperationName == "Creating"
| where resourceGroupName !startswith_cs "aksrnr-"
| project PreciseTimeStamp, minutes=latency/60000.
| render timechart 

// 80 and 95 percentiles
AsyncQoSEvents
| where PreciseTimeStamp > ago(7d)
| where result == "Succeeded"
| where operationName contains "ManagedCluster" and suboperationName == "Creating"
| summarize percentiles(latency / 60000., 80, 95) by isRunner = resourceGroupName startswith_cs "aksrnr-", bin(TIMESTAMP, 1h)
| extend OKR=5
| render timechart with (series=isRunner)

// Anomaly detection for P95
AsyncQoSEvents
| where PreciseTimeStamp > ago(7d)
| where result == "Succeeded"
| where operationName contains "ManagedCluster" and suboperationName == "Creating"
//| where resourceGroupName !startswith_cs "aksrnr-"
| summarize percentiles(latency / 60000., 80, 95) by bin(PreciseTimeStamp, 1h)
| summarize t=make_list(PreciseTimeStamp), p80=make_list(percentile__80), p95=make_list(percentile__95)
//| extend series_decompose_anomalies(p80, 1.5, -1, 'linefit'), 
| extend series_decompose_anomalies(p95, 1.2, -1, 'linefit')
| render timechart
//////////////////////////////////////



//////////////////////////////////////
// Deep investigation of latency, see which leg increased.

let start=ago(7d);
let end=now();
let operation="Creating";
let percentile=95;
let vmType="all";
let timeUnit = iif((end-start)>48h, 1d, 1h);
let operationIDs = (operation: string, start: datetime, end: datetime) {
AsyncQoSEvents
| where PreciseTimeStamp >= start and PreciseTimeStamp < end
| where not(isTestSubscription(subscriptionID))
| where not(isTestRegion(region))
| where operationName contains "ManagedClusterHandler" and operationName !contains "OpenShift"
| extend suboperation = replace(@'None', @'Deleting', suboperationName)
| where suboperation == operation
| where result == "Succeeded"
| project PreciseTimeStamp, operationID
};
let operationIdRowsByVmType = (operation: string, start: datetime, end: datetime, vmType: string) {
operationIDs(operation, start, end)
| join kind=leftouter (FrontEndContextActivity
| where PreciseTimeStamp >= start and PreciseTimeStamp < end
| where not(isTestSubscription(subscriptionID))
| where not(isTestRegion(region))
| where msg contains "sanitized request body:"
| extend vmtype = iif(msg contains '"type":"VirtualMachineScaleSets"', "vmss", "vmas")
| where iif(vmType != "all", vmtype == vmType, true)
) on operationID
| project PreciseTimeStamp, operationID
};
let operationIdRows = operationIdRowsByVmType(operation, start, end, vmType);
let LatencyBreakDown=(operation:string, startTime: datetime , endTime:datetime, unit:timespan) {
operationIdRows
| join (LatencyTraceEvent
| where PreciseTimeStamp > startTime and PreciseTimeStamp <= endTime
| where container == "containerserviceasync"
| where Name == iif(operation == "Deleting", "DeleteManagedClusterAsyncOperation", "PutManagedClusterAsyncOperation")) on operationID
| project SpanID
| join (LatencyTraceEvent
| where PreciseTimeStamp > startTime and PreciseTimeStamp <= endTime
| where container == "containerserviceasync") on $left.SpanID == $right.ParentSpanID
| extend Latency = Latency / 1000.0
| summarize percentile_latency = percentiles(Latency, percentile), count() by bin(PreciseTimeStamp, unit), Name
};
let ValidateAgents=(startTime: datetime , endTime:datetime, unit:timespan) {
operationIdRows
| join (LatencyTraceEvent
| where PreciseTimeStamp > startTime and PreciseTimeStamp <= endTime
| where container == "containerserviceasync"
| where Name == "ValidateAgents") on operationID
| extend Latency = Latency / 1000.0
| summarize percentile_latency = percentiles(Latency, percentile), count() by bin(PreciseTimeStamp, unit), Name
};
let validateAgents = ValidateAgents(start, end, timeUnit);
let LatencyBreakDownTotal = LatencyBreakDown(operation, start, end, 200d);
let majorLatencyName = LatencyBreakDownTotal
| where percentile_latency > 1.0
| project Name;
let countOpByDay = operationIdRows
| summarize count_op = count() by bin(PreciseTimeStamp, timeUnit);
let LatencyByDay = LatencyBreakDown(operation, start, end, timeUnit)
| join kind=inner countOpByDay on PreciseTimeStamp
| where count_ > count_op / 20.0
| project PreciseTimeStamp , Name, percentile_latency , count_, count_op;
LatencyByDay
| where Name !in (majorLatencyName)
| summarize  percentile_latency=sum(percentile_latency) by PreciseTimeStamp
| extend Name="Others"
| union  (LatencyByDay
| where Name in (majorLatencyName))
| union (validateAgents | where Name == iif(operation == "Creating", "ValidateAgents", ""))
| join kind=leftouter validateAgents on PreciseTimeStamp
| extend percentile_latency = iff(operation == "Creating" and Name == "NewDeployment", percentile_latency - percentile_latency1 , percentile_latency )
| project PreciseTimeStamp, Name, percentile_latency
//////////////////////////////////////



//////////////////////////////////////
// AllocationFailed error: vm capacity issue
cluster("Aks").database("AKSprod").AsyncQoSEvents
| where PreciseTimeStamp between (ago(30d)..now())
 and resultType == 1
 and resultCode == "AllocationFailed"
 and resultCodeDependency == "microsoft.compute/virtualmachines"
| summarize FaultCount = count(), SubsCount = dcount(subscriptionID) by bin(PreciseTimeStamp, 1h)
| render timechart

// VM allocation failures in all regions
cluster("Aks").database("AKSprod").AsyncQoSEvents
| where PreciseTimeStamp > ago(60d)
 and resultType == 1
 and resultCode == "AllocationFailed"
 and resultCodeDependency == "microsoft.compute/virtualmachines"
| summarize count() by bin(PreciseTimeStamp, 1d), region
| render timechart  

FrontEndContextActivity
| where PreciseTimeStamp >= ago(7d)
| where msg contains "sanitized request body:"
| extend vmtype = iif(msg contains '"type":"VirtualMachineScaleSets"', "vmss", "vmas")
| summarize count() by vmtype
//////////////////////////////////////

//////////////////////////////////////
// VMStartTimeout errors
AsyncQoSEvents
| where PreciseTimeStamp > ago(7d)
| where operationName == "PutManagedClusterHandler.PUT"
| extend bag = todynamic(propertiesBag)
| extend size = tostring(bag.agentpool_size_0)
| where resultType == 2
| where resultCode == "VMStartTimedOut"
//| project resultType, result, resultCode, resultCodeDependency, resultSubCode, errorDetails
| summarize count() by bin(PreciseTimeStamp, 1h),  region 
| render timechart 
//////////////////////////////////////

//////////////////////////////////////
// Get detail logs for a particular Async operation
AsyncQoSEvents
| where PreciseTimeStamp > ago(5d)
| where result == "Succeeded"
| where operationName contains "ManagedCluster" and suboperationName == "Creating"
| where resourceGroupName == 'qike_eastus'
| project TIMESTAMP, l=round(latency/60000., 2), resourceName, correlationID, operationID, subscriptionID
| join (AsyncContextActivity) on correlationID
| where correlationID == 'd0edb0ea-f223-47fa-9f83-333054000808'
| project PreciseTimeStamp, msg, l, serviceBuild, resourceName, timeNextVisible
| sort by PreciseTimeStamp asc
//////////////////////////////////////


//////////////////////////////////////
// CCP request latencies for 1 cluster
let ccpNS = '5f409a76e74f060001d2fac4'; // Morgan Stanley // '5f234b78546c8e0001c34be2' // stradigi
union cluster('aks').database('AKSccplogs').ControlPlaneEventsNonShoebox, ControlPlaneEvents
| where PreciseTimeStamp >= ago(24h)
| where ccpNamespace == ccpNS
| where category == 'kube-audit'
| extend event=parse_json(tostring(parse_json(properties).log))
| where event.stage == "ResponseComplete"
| where event.verb != "watch"
| where event.responseStatus.code == "200"
// | where event.user.username == "system:serviceaccount:kube-system:kube-proxy"
// | where event.user.username == "nodeclient"
| extend lat=datetime_diff('Millisecond', todatetime(event.stageTimestamp), todatetime(event.requestReceivedTimestamp))
| summarize percentiles(lat, 99, 90, 50) by tostring(event.verb)
//////////////////////////////////////